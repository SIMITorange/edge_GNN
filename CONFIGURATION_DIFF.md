# 配置变更对照表

## 📋 一页纸快速对比：旧 vs 新

### 数据配置 (DataConfig)

| 参数 | 旧值 | 新值 | 变化 | 原因 |
|------|------|------|------|------|
| fourier_features | 8 | 16 | +100% | 更精细的空间频率覆盖 |
| fourier_sigma | 1.0 | 0.5 | -50% | 更高分辨率捕捉尖锐特征 |

**归一化策略变更:**
```
vds:                    standard  →  minmax
ElectrostaticPotential: standard  →  robust
```

---

### 模型配置 (ModelConfig)

| 参数 | 旧值 | 新值 | 变化 | 原因 |
|------|------|------|------|------|
| hidden_dim | 128 | 256 | +100% | 增加特征表达能力 |
| num_layers | 6 | 10 | +67% | 更深的信息传播 |
| dropout | 0.10 | 0.05 | -50% | 减少正则化 |
| heads | 4 | 8 | +100% | 更多专家混合 |
| decoder_hidden | ❌ | 256 | ✨新增 | 解码器MLP容量 |

**总参数变化: 0.5M → 2.5M (+500%)**

---

### 损失配置 (LossConfig)

| 参数 | 旧值 | 新值 | 变化 | 原因 |
|------|------|------|------|------|
| l1_weight | 1.0 | 2.0 | +100% | 强化主损失 |
| relative_l1_weight | 0.3 | 0.8 | +167% | 低幅度区域更高精度 |
| smoothness_weight | 0.05 | 0.08 | +60% | 空间平滑性 |
| gradient_consistency_weight | 0.1 | 0.15 | +50% | 物理约束强化 |
| l2_weight | 1e-5 | **0.0** | -100% | ✅完全移除（允许过拟合） |
| curvature_weight | ❌ | 0.05 | ✨新增 | Laplacian正则化 |

---

### 训练配置 (TrainConfig)

| 参数 | 旧值 | 新值 | 变化 | 原因 |
|------|------|------|------|------|
| epochs | 200 | 400 | +100% | 更充分的训练 |
| batch_size | 1 | 1 | — | 保持不变 |
| lr | 2e-4 | 5e-4 | +150% | 更快初期收敛 |
| weight_decay | 1e-5 | **0.0** | -100% | ✅完全移除 |
| grad_clip | 5.0 | 10.0 | +100% | 允许更大梯度 |
| early_stop_patience | 30 | 60 | +100% | 更多学习机会 |
| use_warmup | ❌ | ✅True | ✨新增 | 学习率预热 |
| warmup_epochs | ❌ | 10 | ✨新增 | 预热持续10个epoch |
| use_scheduler | ❌ | ✅True | ✨新增 | 学习率调度 |
| scheduler_type | ❌ | 'cosine' | ✨新增 | 余弦衰减 |
| min_lr | ❌ | 1e-5 | ✨新增 | 最小学习率 |

---

## 🔄 学习率调度变化

### 原始策略
```
5e-4 ────────────────────────── (固定)
     epoch 0                epoch 200+
```

### 优化后策略
```
5e-4 │     ╱╲ 
     │    ╱  ╲___
4.5e-4           ╲
     │             ╲____
     │                  ╲____  ← 余弦衰减
     │                       ╲_____ ← 1e-5 (最小值)
1e-5 │
     └─────────────────────────────
       0   10      100    200    400  epoch
       ↑   ↑
     预热  主学习阶段
```

**效果**：
- 0-10 epoch: LR线性从0.5e-4增至5e-4
- 10-400 epoch: LR从5e-4余弦衰减至1e-5

---

## 📊 损失函数权重对比

### 旧权重分布
```
l1_weight:        ■■■■■■■■■■ (1.0)
rel_l1_weight:    ■■■ (0.3)
smoothness:       ■ (0.05)
grad_consistency: ■■ (0.1)
━━━━━━━━━━━━━━━
总和: 1.45
```

### 新权重分布
```
l1_weight:        ■■■■■■■■■■■■■■■■■■■■ (2.0) ← 翻倍
rel_l1_weight:    ■■■■■■■■ (0.8)         ← 大幅增加
smoothness:       ■■ (0.08)              ← 加强
grad_consistency: ■■■ (0.15)             ← 加强
curvature:        ■■ (0.05)              ← 新增
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
总和: 3.78 (+161%增加)
```

**影响**: 模型被强制更好地拟合数据和物理约束

---

## 🎯 关键改进点总结

```
┌─────────────────────────────────────────────────┐
│ 归一化 (Normalization)                          │
├─────────────────────────────────────────────────┤
│ ❌ Standard缩放 (vds, V)                        │
│ ✅ Robust缩放 (对异常值更鲁棒)                  │
│ ✅ MinMax缩放 (保留相对关系)                     │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│ 模型 (Model)                                     │
├─────────────────────────────────────────────────┤
│ • hidden_dim: 128 → 256 (2倍)                   │
│ • num_layers: 6 → 10 (1.67倍)                  │
│ • dropout: 0.1 → 0.05 (减半)                    │
│ • heads: 4 → 8 (2倍)                            │
│ • 总参数: 0.5M → 2.5M (5倍)                     │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│ 损失函数 (Loss)                                 │
├─────────────────────────────────────────────────┤
│ • 主损失权重增加 (强化拟合)                      │
│ • 相对损失权重增加 (细节准确)                    │
│ • 物理约束权重增加 (约束满足)                    │
│ • 移除L2正则 (允许过拟合)                       │
│ • 新增曲率项 (平滑约束)                         │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│ 优化策略 (Optimizer)                            │
├─────────────────────────────────────────────────┤
│ • lr: 2e-4 → 5e-4 (快速初期学习)                │
│ • weight_decay: 1e-5 → 0 (完全移除)             │
│ • 新增预热 (10 epoch)                           │
│ • 新增学习率衰减 (余弦曲线)                      │
│ • 训练时长: 200 → 400 epoch                     │
└─────────────────────────────────────────────────┘
```

---

## 📈 性能变化预期

```
维度          原始      优化后    改进方向
─────────────────────────────────────────
拟合能力      中等      高        ↑↑↑
正则化强度    中等      弱        ↓(允许过拟合)
物理约束      中等      强        ↑↑
优化精度      一般      优        ↑↑
训练时间      2小时     5小时     ↑(更长)
显存占用      中等      高        ↑
```

---

## ⚡ 快速应用检查清单

- [ ] config.py 中的DataConfig已更新（fourier参数）
- [ ] config.py 中的ModelConfig已更新（容量参数）
- [ ] config.py 中的LossConfig已更新（权重）
- [ ] config.py 中的TrainConfig已更新（优化参数）
- [ ] train.py 中的strategy_map已更新
- [ ] train.py 中的CompositeLoss初始化已更新
- [ ] train.py 中的Trainer初始化已更新（调度参数）
- [ ] src/models/gnn_model.py 已更新（模型容量）
- [ ] src/training/losses.py 已添加_laplacian_smoothness和更新CompositeLoss
- [ ] src/training/trainer.py 已添加学习率调度逻辑
- [ ] 所有文件已通过语法检查 ✅

---

## 🔑 核心数字一览

| 指标 | 旧值 | 新值 | 倍数 |
|------|------|------|------|
| 模型参数 | 0.5M | 2.5M | 5× |
| 隐层维度 | 128 | 256 | 2× |
| 网络深度 | 6层 | 10层 | 1.67× |
| 解码头数 | 4 | 8 | 2× |
| Fourier特征 | 8 | 16 | 2× |
| 损失权重和 | 1.45 | 3.78 | 2.61× |
| 训练轮数 | 200 | 400 | 2× |
| 初始学习率 | 2e-4 | 5e-4 | 2.5× |
| 最小学习率 | 固定 | 1e-5 | 动态 |

---

## 🚀 立即开始

```bash
# 1. 验证配置
python -c "from config import get_default_configs; print('✅ Config loaded successfully')"

# 2. 启动训练
python train.py

# 3. 监控进度
tensorboard --logdir=logs
```

---

## 📞 常见疑问

**Q: 为什么参数增加5倍会改善拟合？**
A: 物理场的非线性程度高，小模型已达容量瓶颈。增加参数打开新的表示空间。

**Q: 为什么移除weight decay？**
A: 当前是欠拟合而非过拟合，L2正则只会让问题更差。

**Q: 为什么损失权重增加这么多？**
A: 权重增加强制模型更好地拟合目标，可以克服原有模型的不足。

**Q: 显存会不会爆？**
A: 可能。如果OOM，降低hidden_dim到192或num_layers到8。

**Q: 多久能看到效果？**
A: 第50-100 epoch应该能看到明显改善。

---

*此表格保持最新 - 2025-12-01*
