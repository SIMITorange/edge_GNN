# 物理场GNN模型优化方案总结

## 目标
改进边基GNN模型对物理场分布的拟合能力，实现最优拟合（可接受过拟合）。

---

## 一、数据归一化策略优化

### 原始策略问题
- 某些字段使用不适合的归一化方法
- 没有充分考虑物理量的特性和分布特点

### 优化后的归一化策略

| 字段 | 旧方法 | 新方法 | 理由 |
|------|-------|--------|------|
| x, y | minmax | minmax | ✓保持不变（保留空间边界） |
| doping | log_standard | log_standard | ✓保持不变（掺杂浓度指数分布） |
| vds | standard | minmax | 改进：相对电位，缩放到 [0,1] |
| ElectrostaticPotential | standard | **robust** | 改进：对异常值更鲁棒，避免被极值支配 |
| ElectricField_x/y | robust | **robust** | ✓保持（场强度有尖峰） |
| SpaceCharge | robust | **robust** | ✓保持（空间电荷有尖峰） |

**Robust缩放优势**：使用中位数和四分位距(IQR)而非均值和方差，对异常值更有容忍度，适合物理场中存在尖锐特征的情况。

---

## 二、模型架构优化

### 参数对比

| 参数 | 旧值 | 新值 | 增幅 | 目的 |
|------|------|------|------|------|
| hidden_dim | 128 | 256 | 2.0x | 增加特征表达能力 |
| num_layers | 6 | 10 | 1.67x | 更深的信息传播 |
| dropout | 0.10 | 0.05 | 0.5x | 减少正则化，允许过拟合 |
| heads | 4 | 8 | 2.0x | 更多专家混合 |
| decoder_hidden | 无 | 256 | 新增 | 解码器MLP隐层容量 |

### 架构改进细节

1. **编码器增强**
   - 从简单的单层映射升级为两层GELU激活
   - 增加中间层Dropout，提高特征多样性

2. **解码器多头专家改进**
   - 每个专家从2层升级为3层（隐层/2的维度）
   - 门控网络也升级为2层（增加自适应能力）
   - 更灵活地混合多个专家的输出

3. **Fourier特征增强**
   - 从8个升级到16个频率特征
   - Sigma从1.0降至0.5，获得更精细的频率覆盖
   - 能更好地捕捉局部的尖锐变化

### 总参数量估计
- 原始模型：~0.5M参数
- 优化后模型：~2.5M参数（5倍增长）
- 足以拟合复杂的物理场分布

---

## 三、损失函数优化

### 加权组件调整

| 损失项 | 旧权重 | 新权重 | 调整幅度 | 效果 |
|--------|--------|--------|----------|------|
| L1损失 | 1.0 | 2.0 | +100% | 强调绝对误差 |
| 相对L1 | 0.3 | 0.8 | +167% | 强调低幅度区域的相对精度 |
| 平滑性 | 0.05 | 0.08 | +60% | 场的连续性 |
| 梯度一致 | 0.1 | 0.15 | +50% | 物理约束（-∇V = E） |

### 新增损失项

#### 1. 曲率正则化（新增）
- 权重：0.05
- **作用**：通过Laplacian平滑项，约束二阶导数
- **公式**：$L_{curv} = \sum_{(i,j) \in \mathcal{E}} (V_i - V_j)^2$
- **好处**：比一阶TV更强的平滑约束，保留尖锐特征同时避免噪声

#### 2. 移除L2正则化
- 旧值：1e-5
- 新值：0（完全移除）
- **理由**：L2正则化（权重衰减）会限制模型参数，不利于过拟合拟合目标

### 损失函数调优理由

1. **主要损失权重增加** → 直接优化预测准确度
2. **相对损失权重大幅增加** → 在低幅度区域（如场强弱处）也要求高精度
3. **物理约束强化** → 确保E场与V场满足物理关系
4. **曲率项添加** → 避免振荡和高频噪声，同时保留物理特征
5. **移除L2正则** → 不限制参数大小，允许模型自由学习

---

## 四、优化器和学习率策略

### 基础优化器设置

```python
torch.optim.AdamW(
    model.parameters(),
    lr=5e-4,        # 从2e-4增加到5e-4（更快收敛）
    weight_decay=0.0  # 从1e-5改为0（完全移除L2）
)
```

### 学习率调度策略（新增）

#### 阶段1：预热（Warmup）- 前10个epoch
- **策略**：线性预热从0.1×lr到1.0×lr
- **目的**：避免早期不稳定，让模型逐步进入学习过程
- **公式**：$lr_t = 0.1 \cdot lr + 0.9 \cdot lr \cdot \frac{t}{T_{warmup}}$

#### 阶段2：余弦衰减（Cosine Annealing）- 后390个epoch
- **策略**：余弦曲线从初始lr衰减到最小值
- **最小lr**：1e-5
- **公式**：$lr_t = \eta_{min} + \frac{\eta_0 - \eta_{min}}{2}(1 + \cos(\pi \cdot \frac{t}{T}))$
- **目的**：
  - 快速学习关键特征（早期）
  - 精细调整权重（后期）
  - 避免学习率过小导致卡住

### 梯度裁剪
- 从5.0增加到10.0
- 允许更大的梯度更新，加速学习

---

## 五、训练超参数优化

| 参数 | 旧值 | 新值 | 理由 |
|------|------|------|------|
| epochs | 200 | 400 | 更长训练时间以充分拟合 |
| early_stop_patience | 30 | 60 | 给予更多机会找到最优点 |
| batch_size | 1 | 1 | ✓保持不变（图过大） |
| lr | 2e-4 | 5e-4 | 更快收敛 |
| weight_decay | 1e-5 | 0 | 消除正则化 |

---

## 六、Fourier特征优化

### 升级原因

**现象**：物理场中存在尖锐的边界层和接面，局部信息丰富

**解决方案**：
- **特征数增加**：8 → 16
  - 覆盖更多频率范围：$\omega_k = \frac{2\pi k}{2\pi} = k$，$k=1..16$
  - 对尖锐过渡的频率敏感性更高
  
- **Sigma减小**：1.0 → 0.5
  - 高斯核宽度减小，捕捉更细的空间尺度
  - $\phi_k(x) = \sin(2\pi k \sigma x)$ 其中 $\sigma$ 较小
  - 分辨率提高，但可能增加频率混淆，需配合更强模型

---

## 七、综合优化策略对比

### 性能预期

| 指标 | 优化前 | 优化后 | 改进 |
|------|--------|--------|------|
| 模型容量 | ~0.5M参数 | ~2.5M参数 | **5倍** |
| 训练时长 | 200 epochs | 400 epochs | **2倍** |
| 正则化强度 | 中等（L2+Dropout） | 极弱（仅Dropout） | **允许更大过拟合** |
| 优化过程 | 固定LR | 预热+余弦衰减 | **更精细的LR调度** |
| 物理约束 | 相对较弱 | 更强的梯度一致性 | **更好的物理性** |

### 预期改进方向

✅ **训练损失**：显著下降（增加模型容量+减少正则化）
✅ **验证损失**：下降（如果数据充分）或小幅上升（过拟合阶段）
✅ **场的光滑度**：改善（曲率项+平滑性权重增加）
✅ **物理约束**：改善（梯度一致性权重增加）
✅ **局部特征捕捉**：改善（Fourier特征和模型深度增加）

---

## 八、关键优化见解

### 为什么增加容量能帮助拟合物理场？

1. **非线性复杂性**
   - 物理场的非线性程度很高
   - 小模型可能已达到容量瓶颈，增加模型宽度和深度开启新的表示空间

2. **空间异质性**
   - 不同区域的物理过程不同（耗尽区vs中性区）
   - 多头解码器可以为不同区域学习不同的特征组合

3. **多任务学习**
   - 4个预测目标（V, Ex, Ey, SpaceCharge）
   - 共享特征但有不同的解码器允许灵活的任务依赖关系

### 为什么强化损失权重而不是增加正则化？

- **传统思路**：过拟合 → 增加正则化
- **当前问题**：模型根本拟合不到数据
- **新思路**：先让模型充分学习，再考虑泛化

如果数据足够好，充分拟合训练数据能学到物理规律。如果泛化不好，可能是数据问题而非模型问题。

---

## 九、使用建议

### 训练前检查清单

- [ ] 确认数据集充分大（建议>100个mesh）
- [ ] GPU显存足够（2.5M参数 + 大图 ≈ 需要>6GB）
- [ ] 保留验证集用于早停监控
- [ ] 定期检查TensorBoard日志

### 训练期间监控指标

1. **loss/total** → 应持续下降（至少到epoch 100+）
2. **val/loss/total** → 指示过拟合程度（温和上升可接受）
3. **各字段的相对误差** → 应均匀改善
4. **consistency/grad** → 应保持较低值

### 如果效果仍不理想

1. **检查数据质量**
   - 网格是否适当？
   - 物理求解是否准确？

2. **进一步增加容量**
   - hidden_dim: 256 → 512
   - num_layers: 10 → 15

3. **调整Fourier参数**
   - fourier_features: 16 → 32
   - fourier_sigma: 0.5 → 0.3

4. **调整损失权重**
   - 如果某个字段拟合差，增加其权重
   - smoothness_weight: 0.08 → 0.15

5. **采用两阶段训练**
   - 第一阶段：w/o梯度一致性，快速学习基本模式
   - 第二阶段：加入梯度一致性精细化

---

## 十、文件修改清单

✅ `config.py` - 更新所有超参数配置
✅ `train.py` - 更新归一化策略和优化器初始化
✅ `src/models/gnn_model.py` - 增强编码器、解码器和模型容量
✅ `src/training/losses.py` - 添加曲率项和增加权重
✅ `src/training/trainer.py` - 实现学习率调度（预热+余弦衰减）

---

## 总结

本优化方案通过以下策略实现物理场的最优拟合：

1. **归一化优化** → 更好地处理物理量的多尺度特性
2. **模型增强** → 5倍参数增长，更强表达能力
3. **损失重设计** → 强化拟合和物理约束
4. **学习率调度** → 预热+余弦衰减，更精细的优化
5. **移除正则化** → 允许过拟合，充分学习数据

**预期结果**：显著改善物理场拟合质量，特别是：
- 电势和电场的空间连续性
- 接面处的尖锐特征捕捉
- 多物理量间的一致性

---

*优化方案完成于 2025-12-01*
